---
title: "Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework"

authors:
  - Yuan Xia
  - Akanksha Atrey
  - Fadoua Khmaissia
  - Kedar S. Namjoshi

author_notes: []

date: "2025-04-28T00:00:00Z"
publishDate: "2025-04-28T00:00:00Z"

publication_types: ["article-journal"]

publication: "arXiv preprint arXiv:2504.20213"
publication_short: "arXiv:2504.20213"

abstract: |
  We investigate whether large language models (LLMs) can master formal
  reasoning by focusing on the technically demanding task of constructing
  Boolean-logic proofs.  Given a set of assumptions and a goal, a trained LLM
  produces a proof whose correctness is verified by an automated checker.  To
  overcome the scarcity of real proofs, we devise a randomized procedure for
  synthesizing valid proofs and introduce **Template Transformation**, a data
 -augmentation technique that bolsters the model’s ability to handle complex
  logical expressions.  We propose black-box tests to quantify an LLM’s
  reasoning ability and show that accuracy is high for short proofs but falls
  as proof depth grows.  Notably, template transformation yields accuracy
  gains even for smaller models, underscoring its scale-independent benefit.

tags:
  - Large Language Models
  - Formal Logic
  - Proof Generation

featured: false

doi: ""

# External links
url_pdf: "https://arxiv.org/pdf/2504.20213"
url_code: ""
url_poster: ""
url_project: ""
url_slides: ""
url_source: ""
url_video: ""

image:
  caption: ""
  focal_point: ""
  preview_only: false

projects: []

slides: ""
---
{{% callout note %}}
Click the _Cite_ button above to import the BibTeX entry.
{{% /callout %}}

_Add full text, supplementary notes, or rich content here when desired._
